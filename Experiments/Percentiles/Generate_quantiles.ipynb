{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {\n",
    "    'project_id': 'p1',\n",
    "    'genes': [\n",
    "        {\n",
    "            'name': 'gene_name1',\n",
    "            'cell_types': [\n",
    "                {'name': 'cell_type1', 'percentil': 81.9},\n",
    "                {'name': 'cell_type2', 'percentil': 0.0}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'gene_name2',\n",
    "            'cell_types': [\n",
    "                {'name': 'cell_type1', 'percentil': 56.9},\n",
    "                {'name': 'cell_type2', 'percentil': 98.0}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles_from_project(project_ID):\n",
    "    \n",
    "    # Check if percentil already exists\n",
    "    if os.path.exists(f'../SingleCell-Files/percentiles/{project_ID}.percentiles.csv'):\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Reading files for {project_ID}...\")\n",
    "    # Read project matrix and metadata\n",
    "    matrix, metadata, cell_names, gen_names = read_files(project_ID)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if matrix is None:\n",
    "        remove_project_files(project_ID)\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Getting cell type groups for {project_ID}...\")\n",
    "    # Generate cell type groups with metadata\n",
    "    cell_type_groups = get_cell_type_groups(metadata, cell_names)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Generating percentiles for {project_ID}...\")\n",
    "    # Get mean percentiles of each cell type\n",
    "    get_percentiles(matrix, cell_type_groups)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Percentiles created for {project_ID}!\")\n",
    "    \n",
    "    # Remove project files, we don't need them anymore\n",
    "    remove_project_files(project_ID)\n",
    "    \n",
    "    return cell_type_groups, gen_names['Gen_Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(project_ID):\n",
    "    # Download matrix using ontology link\n",
    "    download_matrix(project_ID)\n",
    "    \n",
    "    # Read matrix\n",
    "    matrix_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx'\n",
    "    matrix = mmread(matrix_file_name).transpose()\n",
    "    \n",
    "    # Read metadata\n",
    "    metadata = pd.read_csv(f'https://www.ebi.ac.uk/gxa/sc/experiment/{project_ID}/download?fileType=experiment-design&accessKey=', sep='\\t')\n",
    "    \n",
    "    if 'Sample Characteristic[cell type]' not in metadata.columns:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    metadata = metadata[['Assay', 'Sample Characteristic[cell type]']]\n",
    "    \n",
    "    # Read cell names\n",
    "    cells_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_cols'\n",
    "    cell_names = pd.read_csv(cells_file_name, header=None, names=['Assay'])\n",
    "    \n",
    "    # Read gen names\n",
    "    gens_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_rows'\n",
    "    gen_names = pd.read_csv(gens_file_name, header=None, names=['Gen_Name'])\n",
    "    \n",
    "    gen_names['Gen_Name'] = gen_names['Gen_Name'].apply(lambda x: x.split('\\t')[1])\n",
    "    \n",
    "    return matrix, metadata, cell_names, gen_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_matrix(project_ID):\n",
    "    \n",
    "    server_name = 'http://194.4.103.244:3030'\n",
    "    service_name = 'ds'\n",
    "    request_url = server_name + '/' + service_name\n",
    "    \n",
    "    path_to_links = '../SingleCell-Files/downloads/'\n",
    "    \n",
    "    query = '''\n",
    "        PREFIX a: <http://www.semanticweb.org/alicia/ontologies/2020/8/singleCellRepositories#> \n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        SELECT \n",
    "            ?normalisedCountsLink ?experimentDesignLink\n",
    "        WHERE\n",
    "        {\n",
    "        '''\\\n",
    "        + \\\n",
    "        f'''\n",
    "            ?projectID rdf:type a:Project ;\n",
    "                       a:PR.hasProjectID \"{project_ID}\" ;\n",
    "                       a:SPR.hasNormalisedCountsLink ?normalisedCountsLink ;\n",
    "                       a:SPR.hasExperimentDesignLink ?experimentDesignLink .\n",
    "        '''\\\n",
    "        +\\\n",
    "        '''      \n",
    "        }\n",
    "    '''\n",
    "    response = requests.post(request_url,\n",
    "       data={'query': query})\n",
    "    \n",
    "    if not response.json()['results']['bindings']:\n",
    "        return None\n",
    "    \n",
    "    normalisedCountsLink = response.json()['results']['bindings'][0]['normalisedCountsLink']['value'] \n",
    "    \n",
    "    # download the file contents in binary format\n",
    "    response = requests.get(normalisedCountsLink)\n",
    "    \n",
    "    zip_name = path_to_links + project_ID + \".zip\"\n",
    "    \n",
    "    # open method to open a file on your system and write the contents\n",
    "    with open(zip_name, \"wb\") as code:\n",
    "        code.write(response.content)\n",
    "        \n",
    "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx', path=path_to_links)\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx_rows', path=path_to_links)\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx_cols', path=path_to_links)\n",
    "        \n",
    "    os.remove(zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_type_groups(metadata, cell_names):\n",
    "    # Merge both dataframes so we get the cells of the matrix with their corresponding type\n",
    "    cell_types = pd.merge(\n",
    "        cell_names,\n",
    "        metadata,\n",
    "        how=\"inner\",\n",
    "        on='Assay'\n",
    "    )\n",
    "    \n",
    "    # Group by cell type\n",
    "    grouped = cell_types.groupby(by='Sample Characteristic[cell type]')\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    # For each group, assign its name and the index of the matrix for this type\n",
    "    for name, group in grouped:\n",
    "        groups.append({\n",
    "            'name': name,\n",
    "            'index': group.index\n",
    "        })\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles(matrix, cell_type_groups):\n",
    "    for group in cell_type_groups:\n",
    "\n",
    "        print(group['name'])\n",
    "        submatrix = matrix.A[group['index']]\n",
    "        print(submatrix.shape)\n",
    "        mean = np.mean(submatrix, axis=0)\n",
    "                \n",
    "        group['percentiles'] = [percentileofscore(mean, x, 'strict') for x in mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_project_files(project_ID):\n",
    "    matrix_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx'\n",
    "    cells_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_cols'\n",
    "    gens_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_rows'\n",
    "\n",
    "    os.remove(matrix_file_name)\n",
    "    os.remove(cells_file_name)\n",
    "    os.remove(gens_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test percentil creation with a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles created!\n",
      "CPU times: user 1.08 s, sys: 53.3 ms, total: 1.14 s\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# groups, gen_names = get_percentiles_from_project('E-GEOD-100911')\n",
    "groups, gen_names = get_percentiles_from_project('E-MTAB-6386')\n",
    "# groups, gen_names = get_percentiles_from_project('E-GEOD-139324')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for d in [{'gen_name': gen_names}] + [{group['name']: group['percentiles']} for group in groups]:\n",
    "    dic.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_name</th>\n",
       "      <th>leukocyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>35.400328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>87.615272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>62.690683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>52.667414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000938</td>\n",
       "      <td>90.881669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23201</th>\n",
       "      <td>ENSG00000288529</td>\n",
       "      <td>4.369560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23202</th>\n",
       "      <td>ENSG00000288534</td>\n",
       "      <td>47.698871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23203</th>\n",
       "      <td>ENSG00000288550</td>\n",
       "      <td>55.494269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>ENSG00000288558</td>\n",
       "      <td>65.164182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23205</th>\n",
       "      <td>ENSG00000288564</td>\n",
       "      <td>34.361803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              gen_name  leukocyte\n",
       "0      ENSG00000000003  35.400328\n",
       "1      ENSG00000000419  87.615272\n",
       "2      ENSG00000000457  62.690683\n",
       "3      ENSG00000000460  52.667414\n",
       "4      ENSG00000000938  90.881669\n",
       "...                ...        ...\n",
       "23201  ENSG00000288529   4.369560\n",
       "23202  ENSG00000288534  47.698871\n",
       "23203  ENSG00000288550  55.494269\n",
       "23204  ENSG00000288558  65.164182\n",
       "23205  ENSG00000288564  34.361803\n",
       "\n",
       "[23206 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../SingleCell-Files/E-GEOD-100911.percentiles.csv', index=False)\n",
    "# df.to_csv('../SingleCell-Files/E-MTAB-6386.percentiles.csv', index=False)\n",
    "df.to_csv('../SingleCell-Files/E-GEOD-139324.percentiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pertenciles for all projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCEA projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get all SCEA projects from our ontology that have cellular type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = 'http://194.4.103.244:3030'\n",
    "service_name = 'ds'\n",
    "request_url = server_name + '/' + service_name\n",
    "\n",
    "query = '''\n",
    "    PREFIX a: <http://www.semanticweb.org/alicia/ontologies/2020/8/singleCellRepositories#> \n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT \n",
    "        ?projectID\n",
    "    WHERE\n",
    "    {\n",
    "      ?project rdf:type a:Project ;\n",
    "               a:PR.hasProjectID ?projectID ;\n",
    "               a:SPR.isPartOfRepository \"SingleCellExpresionAtlas\" ;\n",
    "               a:SPR.hasCellType ?cellType .                                               \n",
    "    }\n",
    "\n",
    "    GROUP BY ?projectID\n",
    "'''\n",
    "\n",
    "response = requests.post(request_url,\n",
    "   data={'query': query})\n",
    "\n",
    "projects_IDs = []\n",
    "\n",
    "for project in response.json()['results']['bindings']:\n",
    "    project_ID = project['projectID']['value']\n",
    "    \n",
    "    projects_IDs.append(project_ID)\n",
    "\n",
    "len(projects_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the project IDs, we can get the percentile of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99\n"
     ]
    }
   ],
   "source": [
    "n_projects = len(projects_IDs)\n",
    "\n",
    "for n, project_ID in enumerate(projects_IDs):\n",
    "    print(f\"{n+1}/{n_projects}\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    groups, gen_names = get_percentiles_from_project(project_ID)\n",
    "\n",
    "    if groups is None:\n",
    "        clear_output(wait=True)\n",
    "        continue\n",
    "    \n",
    "    dic = {}\n",
    "    for d in [{'gen_name': gen_names}] + [{group['name']: group['percentiles']} for group in groups]:\n",
    "        dic.update(d)\n",
    "    \n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv(f'../SingleCell-Files/percentiles/{project_ID}.percentiles.csv', index=False)\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with 3 projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the schema of the index. Each document will have a title and a content (project genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the index in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "\n",
    "path = \"../SingleCell-Files/index\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "ix = create_in(path, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test the index with 3 projects. 2 of them are studies of blood (E-MTAB-6386 and E-GEOD-139324). So they are suppose to have genes in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../SingleCell-Files/percentiles/E-GEOD-100911.percentiles.csv')\n",
    "df1 = pd.read_csv('../SingleCell-Files/percentiles/E-MTAB-6386.percentiles.csv')\n",
    "df2 = pd.read_csv('../SingleCell-Files/percentiles/E-GEOD-139324.percentiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_genes = df0['gen_name'].tolist()\n",
    "df1_genes = df1['gen_name'].tolist()\n",
    "df2_genes = df2['gen_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the common gens between the projects, and some genes that are exclusive of each project. We will use these genes to test the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "['ENSG00000160695', 'ENSG00000162222', 'ENSG00000134864']\n",
      "['ENSDARG00000000001', 'ENSDARG00000000018', 'ENSDARG00000000019']\n",
      "['ENSG00000287846', 'ENSG00000284732', 'ENSG00000130528']\n",
      "['ENSG00000204572', 'ENSG00000181544', 'ENSG00000164185']\n"
     ]
    }
   ],
   "source": [
    "print(set(df0_genes).intersection(set(df1_genes)).intersection(set(df2_genes)))\n",
    "print(list(set(df1_genes).intersection(set(df2_genes)))[:3])\n",
    "print(df0_genes[:3])\n",
    "print(list(set(df1_genes).difference(set(df2_genes)))[:3])\n",
    "print(list(set(df2_genes).difference(set(df1_genes)))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the three projects to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_document(title=\"E-GEOD-100911\", content=' '.join(df0_genes))\n",
    "writer.add_document(title=\"E-MTAB-6386\", content=' '.join(df1_genes))\n",
    "writer.add_document(title=\"E-GEOD-139324\", content=' '.join(df2_genes))\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do some test queries with the genes saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for gene ENSDARG00000034326\n",
      "CPU times: user 285 µs, sys: 18 µs, total: 303 µs\n",
      "Wall time: 298 µs\n",
      "E-GEOD-100911\n",
      "\n",
      "Searching for gene ENSG00000160695\n",
      "CPU times: user 288 µs, sys: 0 ns, total: 288 µs\n",
      "Wall time: 291 µs\n",
      "E-MTAB-6386\n",
      "E-GEOD-139324\n",
      "\n",
      "Searching for gene ENSG00000287846\n",
      "CPU times: user 250 µs, sys: 15 µs, total: 265 µs\n",
      "Wall time: 269 µs\n",
      "E-MTAB-6386\n",
      "\n",
      "Searching for gene ENSG00000204572\n",
      "CPU times: user 269 µs, sys: 0 ns, total: 269 µs\n",
      "Wall time: 273 µs\n",
      "E-GEOD-139324\n",
      "\n",
      "Searching for projects that contains genes starting with ENS\n",
      "CPU times: user 3.47 s, sys: 54.5 ms, total: 3.53 s\n",
      "Wall time: 3.53 s\n",
      "E-GEOD-100911\n",
      "E-MTAB-6386\n",
      "E-GEOD-139324\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "print(\"Searching for gene ENSDARG00000000001\")\n",
    "\n",
    "qp = QueryParser(\"content\", ix.schema)\n",
    "q = qp.parse(u\"ENSDARG00000000001\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "print()\n",
    "print(\"Searching for gene ENSG00000160695\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000160695\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "print()\n",
    "print(\"Searching for gene ENSG00000287846\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000287846\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "\n",
    "print()        \n",
    "print(\"Searching for gene ENSG00000204572\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000204572\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "        \n",
    "print()\n",
    "print(\"Searching for projects that contains genes starting with ENS\")           \n",
    "\n",
    "q = qp.parse(u\"ENS*\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index with all percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the index in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "\n",
    "path = \"../SingleCell-Files/index\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "ix = create_in(path, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../SingleCell-Files/percentiles/'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    df = pd.read_csv(directory + filename)\n",
    "    \n",
    "    df_genes = df['gen_name'].tolist()\n",
    "    df_cell_types = [x for x in df.columns if x != 'gen_name']\n",
    "    content = df_genes + df_cell_types\n",
    "    \n",
    "    project_id = filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    writer.add_document(title=project_id, content=' '.join(content))\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 277 µs, sys: 15 µs, total: 292 µs\n",
      "Wall time: 296 µs\n",
      "E-GEOD-100058\n",
      "E-MTAB-7303\n",
      "E-GEOD-75140\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "qp = QueryParser(\"content\", ix.schema)\n",
    "q = qp.parse(u\"Neuron\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 69.7 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n",
      "E-MTAB-7678\n",
      "E-GEOD-89232\n",
      "E-GEOD-106973\n",
      "E-GEOD-70580\n",
      "E-MTAB-6051\n",
      "E-MTAB-6505\n",
      "E-MTAB-7052\n",
      "E-GEOD-75140\n",
      "E-MTAB-6945\n",
      "E-CURD-11\n",
      "E-GEOD-75367\n",
      "E-ENAD-13\n",
      "E-GEOD-150728\n",
      "E-CURD-6\n",
      "E-GEOD-83139\n",
      "E-MTAB-6524\n",
      "E-GEOD-89910\n",
      "E-MTAB-7098\n",
      "E-GEOD-100426\n",
      "E-MTAB-6379\n",
      "E-MTAB-7051\n",
      "E-MTAB-5802\n",
      "E-MTAB-7094\n",
      "E-MTAB-6925\n",
      "E-MTAB-6308\n",
      "E-ENAD-21\n",
      "E-MTAB-4850\n",
      "E-MTAB-5661\n",
      "E-GEOD-98556\n",
      "E-GEOD-124858\n",
      "E-MTAB-5530\n",
      "E-MTAB-6970\n",
      "E-MTAB-6108\n",
      "E-GEOD-110499\n",
      "E-MTAB-7311\n",
      "E-ENAD-14\n",
      "E-MTAB-6487\n",
      "E-MTAB-7660\n",
      "E-MTAB-6386\n",
      "E-MTAB-4888\n",
      "E-GEOD-76312\n",
      "E-MTAB-8810\n",
      "E-MTAB-5485\n",
      "E-GEOD-108221\n",
      "E-GEOD-100911\n",
      "E-MTAB-6058\n",
      "E-GEOD-81682\n",
      "E-MTAB-7008\n",
      "E-MTAB-8077\n",
      "E-MTAB-7703\n",
      "E-GEOD-111727\n",
      "E-MTAB-6879\n",
      "E-MTAB-7149\n",
      "E-GEOD-146122\n",
      "E-MTAB-6362\n",
      "E-MTAB-6385\n",
      "E-MTAB-7606\n",
      "E-GEOD-36552\n",
      "E-GEOD-149689\n",
      "E-MTAB-7303\n",
      "E-MTAB-5727\n",
      "E-GEOD-137537\n",
      "E-GEOD-100618\n",
      "E-GEOD-109979\n",
      "E-MTAB-7249\n",
      "E-MTAB-7381\n",
      "E-MTAB-6987\n",
      "E-GEOD-124472\n",
      "E-MTAB-7037\n",
      "E-GEOD-130473\n",
      "E-GEOD-139324\n",
      "E-MTAB-4547\n",
      "E-MTAB-7901\n",
      "E-MTAB-8559\n",
      "E-GEOD-86618\n",
      "E-MTAB-6911\n",
      "E-MTAB-6818\n",
      "E-MTAB-6677\n",
      "E-MTAB-6819\n",
      "E-MTAB-6976\n",
      "E-GEOD-103334\n",
      "E-GEOD-99795\n",
      "E-GEOD-125970\n",
      "E-GEOD-87631\n",
      "E-MTAB-7117\n",
      "E-MTAB-5553\n",
      "E-MTAB-6173\n"
     ]
    }
   ],
   "source": [
    "q = qp.parse(u\"ENS*\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cell types to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
